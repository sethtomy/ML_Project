{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "# weighted KNN, k=10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "svm = LinearSVC()\n",
    "linreg = LinearRegression()\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run every dataset(5 of them) through multiple models to find best model\n",
    "for i in range(1,6):\n",
    "    # put data in pandas dataframe\n",
    "    data = 'datasets/Classification/Data{}/TrainData{}.txt'.format(i, i)\n",
    "    label = 'datasets/Classification/Data{}/TrainLabel{}.txt'.format(i, i)\n",
    "    X = pd.read_csv(data, sep='\\s+', header=None)\n",
    "    y = pd.read_csv(label, header=None)\n",
    "    print()\n",
    "    print('''*** Dataset {} ***'''.format(i))\n",
    "    print('Number of Samples: ' + str(X.shape[0]))\n",
    "    print('Number of Features: ' + str(X.shape[1]))\n",
    "    print('Classes: ' + str(y[0].unique()))\n",
    "    \n",
    "    # fill missing values\n",
    "    if X.isnull().any().any():\n",
    "        # change to nan\n",
    "        X = X[X < 1e99]\n",
    "        # fill linear-ly\n",
    "        X = X.interpolate()\n",
    "        # fill outside values with mean\n",
    "        X = X.fillna(X.mean())\n",
    "\n",
    "    #, stratify=y\n",
    "    # split into 90% train and 10% test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
    "    \n",
    "    # run through each model and print results\n",
    "    knn.fit(X, y.values.flatten())\n",
    "    print('knn: ' + str(knn.score(X_test, y_test)))\n",
    "    svm.fit(X, y.values.flatten())\n",
    "    print('svm: ' + str(svm.score(X_test, y_test)))\n",
    "    linreg.fit(X, y.values.flatten())\n",
    "    print('linear regression: ' + str(linreg.score(X_test, y_test)))\n",
    "    logreg.fit(X, y.values.flatten())\n",
    "    print('logistic regression ' + str(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
